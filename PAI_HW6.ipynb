{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PAI_HW6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2GmvtZVv0mj"
      },
      "source": [
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V3JRTgVnw9O"
      },
      "source": [
        "!pip install face-recognition\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcCL6iA_wgvC"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "from sklearn.cluster import DBSCAN\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa0yipMyHGM0"
      },
      "source": [
        "!pip install mediapipe\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BhTduXfHNXc"
      },
      "source": [
        "import mediapipe as mp\n",
        "import time\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMKJOViCyiQg"
      },
      "source": [
        "filename = 'video30.avi' \n",
        "cap = cv2.VideoCapture(\"./\"+filename)\n",
        "embeddings = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofnF4S6-K_jO"
      },
      "source": [
        "cap = cv2.VideoCapture('./'+filename)\n",
        "pTime = 0\n",
        "counter = 0\n",
        "\n",
        "mpFaceDetection = mp.solutions.face_detection\n",
        "mpDraw = mp.solutions.drawing_utils\n",
        "faceDetection = mpFaceDetection.FaceDetection()\n",
        "encodings = []\n",
        "data = dict()\n",
        "while True:\n",
        "  success, img = cap.read()\n",
        "\n",
        "\n",
        "  if success == False:\n",
        "        print(\"Not found\")\n",
        "        break\n",
        "\n",
        "  imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        " \n",
        "  results = faceDetection.process(imgRGB)\n",
        "  boxes = []\n",
        "  ens = []\n",
        "  if results.detections:\n",
        "    for id, detection in enumerate(results.detections):\n",
        "      bboxC = detection.location_data.relative_bounding_box\n",
        "      ih, iw, ic = img.shape\n",
        "      bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), \\\n",
        "             int(bboxC.width * iw), int(bboxC.height * ih)\n",
        "      # print(bbox)\n",
        "      encoding = face_recognition.face_encodings(img, [(bbox[1], bbox[0]+bbox[2], bbox[1]+bbox[3], bbox[0])])\n",
        "      encodings += encoding\n",
        "      boxes.append(tuple(bbox))\n",
        "\n",
        "  data[counter] = {'frame': img, 'boxes': boxes, 'labels': []}\n",
        "  counter += 1\n",
        "  cTime = time.time()\n",
        "  fps = 1 / (cTime - pTime)\n",
        "  pTime = cTime\n",
        "  cv2.waitKey(1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TyNQJ9Epnnu"
      },
      "source": [
        "# cluster the embeddings\n",
        "print(\"[INFO] clustering...\")\n",
        "clt = DBSCAN(eps=0.45, min_samples=1, metric=\"euclidean\", n_jobs=-1)\n",
        "clt.fit(encodings)\n",
        "# determine the total number of unique faces found in the dataset\n",
        "labelIDs = np.unique(clt.labels_)\n",
        "numUniqueFaces = len(np.where(labelIDs > -1)[0])\n",
        "print(\"[INFO] # unique faces: {}\".format(numUniqueFaces))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieZxsfeQ-bst"
      },
      "source": [
        "arr = list(clt.labels_)\n",
        "for i in data:\n",
        "  if data[i]['boxes'] != []:\n",
        "    for j in data[i]['boxes']:\n",
        "      data[i]['labels'].append(arr.pop(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opil9Hd0_PEt"
      },
      "source": [
        "size = (1920, 1080)\n",
        "out = cv2.VideoWriter('output.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 25, size)\n",
        "\n",
        "for i in data:\n",
        "  img = data[i]['frame']\n",
        "  boxes = data[i]['boxes']\n",
        "  labels = data[i]['labels']\n",
        "  for j in range(len(boxes)):\n",
        "    bbox = boxes[j]\n",
        "    label = labels[j]\n",
        "    cv2.rectangle(img, bbox, (255, 0, 255), 2)\n",
        "    cv2.putText(img, f'{label}', (bbox[0], bbox[1]-50), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 255), 2)\n",
        "  vidout=cv2.resize(img,size)\n",
        "  out.write(vidout)\n",
        "\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMQoA87IY49X"
      },
      "source": [
        "References: https://www.youtube.com/watch?v=jn1HSXVmIrA&t=61s\n",
        "https://www.pyimagesearch.com/2018/07/09/face-clustering-with-python/"
      ]
    }
  ]
}